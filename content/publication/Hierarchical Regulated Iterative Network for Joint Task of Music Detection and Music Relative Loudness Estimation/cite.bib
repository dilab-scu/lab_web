@article{9222227,
  title={Hierarchical Regulated Iterative Network for Joint Task of Music Detection and Music Relative Loudness Estimation}, 
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  volume={29},
  pages={1-13},
  year={2021},
  issn={2329-9290},
  doi={10.1109/TASLP.2020.3030484},
  url={https://ieeexplore.ieee.org/abstract/document/9222227},
  author={Jia, Bijue and Lv, Jiancheng and Peng, Xi and Chen, Yao and Yang, Shenglan},
  keywords={Music detection, music relative loudness estimation, event detection, event localization, neural networks, hierarchical classification},
  abstract={One practical requirement of the music copyright management is the estimation of music relative loudness, which is mostly ignored in existing music detection works. To solve this problem, we study the joint task of music detection and music relative loudness estimation. To be specific, we observe that the joint task has two characteristics, i.e., temporality and hierarchy, which could facilitate to obtain the solution. For example, a tiny fragment of audio is temporally related to its neighbor fragments because they may all belong to the same event, and the event classes of the fragment in the two tasks have a hierarchical relationship. Based on the above observation, we reformulate the joint task as hierarchical event detection and localization problem. To solve this problem, we further propose Hierarchical Regulated Iterative Networks (HRIN), which includes two variants, termed as HRIN-r and HRIN-cr, which are based on recurrent and convolutional recurrent modules. To enjoy the joint task's characteristics, our models employ an iterative framework to achieve encouraging capability in temporal modeling while designing three hierarchical violation penalties to regulate hierarchy. Extensive experiments on the currently largest dataset (i.e., OpenBMAT) show that the promising performance of our HRIN in the segment-level and event-level evaluations.}
  }
